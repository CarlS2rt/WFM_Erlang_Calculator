{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec4335b8-6af5-4fe0-8749-b3301155db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from math import exp, ceil, floor\n",
    "import numpy as np\n",
    "import cx_Oracle\n",
    "from config import oracle_wfm_key\n",
    "import time\n",
    "import datetime as dt\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy.types import String\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import databases as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd69b89-cf4d-416e-b891-843c34332e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ods = db.oracle('cco_wfm',oracle_wfm_key)\n",
    "verint  = db.ssms()\n",
    "service = ['BSSC Billing ALL (new)','BSSC Senior','Commercial COAST','Mooresville_BSSC_Billing','BSSC Sales Cable','BSSC Sales Wireline','Mooresville_BSSC_Sales',\n",
    "            'Bend/Cable Consumer Sales','OB_QCB Bend/Cable Sales','Cable Specialist','OB_OCB_Cable_Con_Spec','Cable Sales Seniors',\n",
    "            'Financial Services Res','Financial Services Bus',\n",
    "            'Wireline Sales and Service','Wireline Service QCB','Wireline Consumer Specialist','Wireline Consumer Triage','Wireline Retention QCB','Wireline Senior Specialist 1',\n",
    "            'Salesforce_Prospect_Residential','Salesforce_Sales_Residential','Salesforce_Service_Residential','Salesforce_Retention_Residential',\n",
    "            'Salesforce_Financial_Services_Res','Salesforce_Financial_Services_Bus']\n",
    "start = '2023-03-01 00:00:00.000'\n",
    "end = '2023-04-27 23:45:00.000'\n",
    "appended_data = []\n",
    "for name in service:\n",
    "    new_query = f'''SELECT \n",
    "                        [Queue],\n",
    "                        [DateTime],\n",
    "                        [Actual_CV],\n",
    "                        [Forecasted_CV],\n",
    "                        [Actual_AHT],\n",
    "                        [Forecasted_AHT]                                             \n",
    "                    FROM [BPMAINDB].[dbo].[V_AdHoc_PerformanceStatistics]\n",
    "                    WHERE ([Queue] = '{name}') AND ([DateTime] BETWEEN '{start}' AND '{end}')\n",
    "                    AND ([UserName] = 'satverintwrkoptmgmt')'''\n",
    "    data = pd.read_sql(new_query, verint)\n",
    "    appended_data.append(data)\n",
    "appended_data = pd.concat(appended_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d19b4f-de55-4e76-876d-08cba63b1c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Queue</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Actual_CV</th>\n",
       "      <th>Forecasted_CV</th>\n",
       "      <th>Actual_AHT</th>\n",
       "      <th>Forecasted_AHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>Continuum_Bus_FS</td>\n",
       "      <td>Salesforce_Financial_Services_Bus</td>\n",
       "      <td>2023-04-27 23:15:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>Continuum_Bus_FS</td>\n",
       "      <td>Salesforce_Financial_Services_Bus</td>\n",
       "      <td>2023-04-27 23:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>Continuum_Bus_FS</td>\n",
       "      <td>Salesforce_Financial_Services_Bus</td>\n",
       "      <td>2023-04-27 23:45:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Team                              Queue            DateTime  \\\n",
       "5561  Continuum_Bus_FS  Salesforce_Financial_Services_Bus 2023-04-27 23:15:00   \n",
       "5562  Continuum_Bus_FS  Salesforce_Financial_Services_Bus 2023-04-27 23:30:00   \n",
       "5563  Continuum_Bus_FS  Salesforce_Financial_Services_Bus 2023-04-27 23:45:00   \n",
       "\n",
       "      Actual_CV  Forecasted_CV  Actual_AHT  Forecasted_AHT  \n",
       "5561        0.0            NaN         0.0             NaN  \n",
       "5562        0.0            NaN         0.0             NaN  \n",
       "5563        0.0            NaN         0.0             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_dict = {'BSSC Billing ALL (new)' : 'Commercial_Billing','BSSC Senior' : 'Commercial_Billing','Commercial COAST' : 'Commercial_Billing','Mooresville_BSSC_Billing' : 'Commercial_Billing',\n",
    "        'BSSC Sales Cable' : 'Commercial_Sales','BSSC Sales Wireline' : 'Commercial_Sales','Mooresville_BSSC_Sales' : 'Commercial_Sales',\n",
    "        'Bend/Cable Consumer Sales' : 'Cable_Sales','OB_QCB Bend/Cable Sales' : 'Cable_Sales','Cable Specialist' : 'Cable_Retention','OB_OCB_Cable_Con_Spec' : 'Cable_Retention',\n",
    "        'Cable Sales Seniors' : 'Cable_Seniors',\n",
    "        'Financial Services Res' : 'Residential_FS','Financial Services Bus' : 'Commercial_FS',\n",
    "        'Wireline Sales and Service' : 'Wireline_Sales','Wireline Service QCB' : 'Wireline_Sales',\n",
    "        'Wireline Consumer Specialist' : 'Wireline_Retention','Wireline Consumer Triage' : 'Wireline_Retention','Wireline Retention QCB' : 'Wireline_Retention',\n",
    "        'Wireline Senior Specialist 1': 'Wireline_Seniors','Salesforce_Prospect_Residential': 'Continuum_Sales','Salesforce_Sales_Residential': 'Continuum_Sales',\n",
    "        'Salesforce_Service_Residential': 'Continuum_Sales','Salesforce_Retention_Residential': 'Continuum_Retention','Salesforce_Financial_Services_Res': 'Continuum_Res_FS',\n",
    "        'Salesforce_Financial_Services_Bus': 'Continuum_Bus_FS'}\n",
    "appended_data['Team'] = appended_data['Queue'].map(team_dict)\n",
    "appended_data = appended_data.reindex(columns=['Team'] + list(appended_data.columns[:-1]))\n",
    "appended_data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ae0ff7-e77b-4920-998a-fea7800eac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data['Actual_Workload'] = appended_data['Actual_AHT'] * appended_data['Actual_CV']\n",
    "appended_data['Actual_Workload'] = appended_data['Actual_Workload'].replace(0, np.nan)\n",
    "appended_data['Forecasted_Workload'] = appended_data['Forecasted_AHT'] * appended_data['Forecasted_CV']\n",
    "appended_data['Forecasted_Workload'] = appended_data['Forecasted_Workload'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ba22dd-436a-4cd0-8a7e-aa24098e1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "team = ['Commercial_Billing','Commercial_Sales','Cable_Sales','Cable_Retention','Cable_Seniors','Residential_FS','Commercial_FS',\n",
    "        'Wireline_Sales','Wireline_Retention','Wireline_Seniors','Continuum_Sales','Continuum_Retention','Continuum_Res_FS','Continuum_Bus_FS']\n",
    "dfs = []\n",
    "for t in team:\n",
    "    team_group = appended_data.loc[(appended_data['Team']  == t)]\n",
    "    actual_cv = team_group.groupby(['Team','DateTime'])['Actual_CV'].sum()\n",
    "    actual_cv = actual_cv.reset_index()\n",
    "    actual_cv.set_index('DateTime', inplace=True) # set the index to the 'DateTime' column\n",
    "    actual_cv = actual_cv.resample('30 min').sum() # remove the 'on' parameter\n",
    "    actual_cv.reset_index(inplace=True)\n",
    "    actual_cv.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    forecasted_cv = team_group.groupby(['Team','DateTime'])['Forecasted_CV'].sum()\n",
    "    forecasted_cv = forecasted_cv.reset_index()\n",
    "    forecasted_cv.set_index('DateTime', inplace=True) # set the index to the 'DateTime' column\n",
    "    forecasted_cv = forecasted_cv.resample('30 min').sum() # remove the 'on' parameter\n",
    "    forecasted_cv.reset_index(inplace=True)\n",
    "    forecasted_cv.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    grouped_aht = team_group.groupby(['Team','DateTime'])['Actual_Workload'].sum()\n",
    "    grouped_aht = grouped_aht.reset_index()\n",
    "    grouped_aht['Actual_Workload'] = grouped_aht['Actual_Workload'].replace(0, np.nan)\n",
    "    grouped_aht.set_index('DateTime', inplace=True) # set the index to the 'DateTime' column\n",
    "    grouped_aht = grouped_aht.resample('30 min').sum() # remove the 'on' parameter\n",
    "    grouped_cv = team_group.groupby(['Team','DateTime'])['Actual_CV'].sum()\n",
    "    grouped_cv = grouped_cv.reset_index()\n",
    "    grouped_cv.set_index('DateTime', inplace=True) # set the index to the 'DateTime' column\n",
    "    grouped_cv = grouped_cv.resample('30 min').sum() # remove the 'on' parameter\n",
    "    actual_aht = grouped_aht.merge(grouped_cv, on='DateTime', how='left')\n",
    "    actual_aht['Actual_AHT'] = actual_aht['Actual_Workload'] / actual_aht['Actual_CV']\n",
    "    actual_aht = actual_aht.drop(columns=['Actual_Workload','Actual_CV'])\n",
    "    actual_aht.reset_index(inplace=True)\n",
    "    actual_aht.set_index('DateTime', inplace=True)\n",
    "    actual_aht['Actual_AHT'] = actual_aht['Actual_AHT'].fillna(0)\n",
    "    actual_aht['Actual_AHT'] = round(actual_aht['Actual_AHT'])\n",
    "    \n",
    "    grouped_faht = team_group.groupby(['Team','DateTime'])['Forecasted_Workload'].sum()\n",
    "    grouped_faht = grouped_faht.reset_index()\n",
    "    grouped_faht['Forecasted_Workload'] = grouped_faht['Forecasted_Workload'].replace(0, np.nan)\n",
    "    grouped_faht.set_index('DateTime', inplace=True) # set the index to the 'DateTime' column\n",
    "    grouped_faht = grouped_faht.resample('30 min').sum() # remove the 'on' parameter\n",
    "    grouped_fcv = team_group.groupby(['Team','DateTime'])['Forecasted_CV'].sum()\n",
    "    grouped_fcv = grouped_fcv.reset_index()\n",
    "    grouped_fcv.set_index('DateTime', inplace=True) # set the index to the 'DateTime' column\n",
    "    grouped_fcv = grouped_fcv.resample('30 min').sum() # remove the 'on' parameter\n",
    "    forecasted_aht = grouped_faht.merge(grouped_fcv, on='DateTime', how='left')\n",
    "    forecasted_aht['Forecasted_AHT'] = forecasted_aht['Forecasted_Workload'] / forecasted_aht['Forecasted_CV']\n",
    "    forecasted_aht = forecasted_aht.drop(columns=['Forecasted_Workload','Forecasted_CV'])\n",
    "    forecasted_aht.reset_index(inplace=True)\n",
    "    forecasted_aht.set_index('DateTime', inplace=True)\n",
    "    forecasted_aht['Forecasted_AHT'] = forecasted_aht['Forecasted_AHT'].fillna(0)\n",
    "    forecasted_aht['Forecasted_AHT'] = round(forecasted_aht['Forecasted_AHT'])\n",
    "    \n",
    "    cv = actual_cv.merge(forecasted_cv, on=['DateTime'], how='left')\n",
    "    aht = actual_aht.merge(forecasted_aht, on=['DateTime'], how='left')\n",
    "    table = cv.merge(aht, on=['DateTime'], how='left')\n",
    "    table['Team'] = t\n",
    "    table = table.reindex(columns=['Team'] + list(table.columns[:-1]))\n",
    "    dfs.append(table)\n",
    "\n",
    "call_data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31947efb-6d74-4136-af15-24234266a628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Time_Interval</th>\n",
       "      <th>Actual_CV</th>\n",
       "      <th>Forecasted_CV</th>\n",
       "      <th>Actual_AHT</th>\n",
       "      <th>Forecasted_AHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commercial_Billing</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Commercial_Billing</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>00:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commercial_Billing</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>00:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Commercial_Billing</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>00:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Commercial_Billing</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>00:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Team        Date      Time Time_Interval  Actual_CV  \\\n",
       "0  Commercial_Billing  2023-03-01  00:00:00         00:30        0.0   \n",
       "1  Commercial_Billing  2023-03-01  00:30:00         00:30        0.0   \n",
       "2  Commercial_Billing  2023-03-01  01:00:00         00:30        0.0   \n",
       "3  Commercial_Billing  2023-03-01  01:30:00         00:30        0.0   \n",
       "4  Commercial_Billing  2023-03-01  02:00:00         00:30        0.0   \n",
       "\n",
       "   Forecasted_CV  Actual_AHT  Forecasted_AHT  \n",
       "0            0.0         0.0             0.0  \n",
       "1            0.0         0.0             0.0  \n",
       "2            0.0         0.0             0.0  \n",
       "3            0.0         0.0             0.0  \n",
       "4            0.0         0.0             0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_data.reset_index(inplace=True)\n",
    "call_data['Date'] = call_data['DateTime'].dt.date\n",
    "call_data['Time'] = call_data['DateTime'].dt.time\n",
    "call_data = call_data.drop('DateTime', axis=1)\n",
    "call_data['Time_Interval'] = '00:30'\n",
    "call_data = call_data[['Team', 'Date', 'Time', 'Time_Interval', 'Actual_CV', 'Forecasted_CV', 'Actual_AHT', 'Forecasted_AHT']]\n",
    "call_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a903465-c856-4fb2-8552-c25d0974b759",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Erlang Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f49e884-595f-4052-8423-e40ad4c00156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErlangC:\n",
    "    \"\"\"\n",
    "    Computes the number of positions required to attend a number of transactions in a\n",
    "    queue system based on erlangc.rst. Implementation inspired on:\n",
    "    https://lucidmanager.org/data-science/call-centre-workforce-planning-erlang-c-in-r/\n",
    "    Parameters\n",
    "    ----------\n",
    "    transactions: float,\n",
    "        The number of total transactions that comes in an interval.\n",
    "    aht: float,\n",
    "        Average handling time of a transaction (minutes).\n",
    "    asa: float,\n",
    "        The required average speed of answer (minutes).\n",
    "    interval: int,\n",
    "        Interval length (minutes) where the transactions come in\n",
    "    shrinkage: float,\n",
    "        Percentage of time that an operator unit is not available.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transactions: float, aht: float, asa: float,\n",
    "                 interval: int, shrinkage=0.0,\n",
    "                 **kwargs):\n",
    "\n",
    "        if transactions <= 0:\n",
    "            raise ValueError(\"transactions can't be smaller or equals than 0\")\n",
    "\n",
    "        if aht <= 0:\n",
    "            raise ValueError(\"aht can't be smaller or equals than 0\")\n",
    "\n",
    "        if asa <= 0:\n",
    "            raise ValueError(\"asa can't be smaller or equals than 0\")\n",
    "\n",
    "        if interval <= 0:\n",
    "            raise ValueError(\"interval can't be smaller or equals than 0\")\n",
    "\n",
    "        if shrinkage < 0 or shrinkage >= 1:\n",
    "            raise ValueError(\"shrinkage must be between in the interval [0,1)\")\n",
    "\n",
    "        self.n_transactions = transactions\n",
    "        self.aht = aht / 60  # Convert aht from seconds to minutes\n",
    "        self.interval = interval\n",
    "        self.asa = asa\n",
    "        self.intensity = (self.n_transactions / self.interval) * self.aht\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "\n",
    "    def waiting_probability(self, positions: int, scale_positions: bool = False):\n",
    "        \"\"\"\n",
    "        Returns the probability of waiting in the queue\n",
    "        Parameters\n",
    "        ----------\n",
    "        positions: int,\n",
    "            The number of positions to attend the transactions.\n",
    "        scale_positions: bool, default=False\n",
    "            Set it to True if the positions were calculated using shrinkage.\n",
    "        \"\"\"\n",
    "\n",
    "        if scale_positions:\n",
    "            productive_positions = floor((1 - self.shrinkage) * positions)\n",
    "        else:\n",
    "            productive_positions = positions\n",
    "\n",
    "        erlang_b_inverse = 1\n",
    "        for position in range(1, productive_positions + 1):\n",
    "            erlang_b_inverse = 1 + (erlang_b_inverse * position / self.intensity)\n",
    "\n",
    "        erlang_b = 1 / erlang_b_inverse\n",
    "        return productive_positions * erlang_b / (productive_positions - self.intensity * (1 - erlang_b))\n",
    "\n",
    "    def service_level(self, positions: int, scale_positions: bool = False):\n",
    "        \"\"\"\n",
    "        Returns the expected service level given a number of positions\n",
    "        Parameters\n",
    "        ----------\n",
    "        positions: int,\n",
    "            The number of positions attending.\n",
    "        scale_positions: bool, default = False\n",
    "            Set it to True if the positions were calculated using shrinkage.\n",
    "        \"\"\"\n",
    "        if scale_positions:\n",
    "            productive_positions = floor((1 - self.shrinkage) * positions)\n",
    "        else:\n",
    "            productive_positions = positions\n",
    "\n",
    "        probability_wait = self.waiting_probability(productive_positions, scale_positions=False)\n",
    "        exponential = exp(-(productive_positions - self.intensity) * (self.asa / self.aht))\n",
    "        return max(0, 1 - (probability_wait * exponential))\n",
    "\n",
    "    def achieved_occupancy(self, positions: int, scale_positions: bool = False):\n",
    "        \"\"\"\n",
    "        Returns the expected occupancy of positions\n",
    "        Parameters\n",
    "        ----------\n",
    "        positions: int,\n",
    "            The number of raw positions\n",
    "        scale_positions: bool, default=False\n",
    "            Set it to True if the positions were calculated using shrinkage.\n",
    "        \"\"\"\n",
    "        if scale_positions:\n",
    "            productive_positions = floor((1 - self.shrinkage) * positions)\n",
    "        else:\n",
    "            productive_positions = positions\n",
    "\n",
    "        return self.intensity / productive_positions\n",
    "\n",
    "    def required_positions(self, service_level: float, max_occupancy: float = 1.0):\n",
    "        \"\"\"\n",
    "        Computes the requirements using erlangc.rst\n",
    "        Parameters\n",
    "        ----------\n",
    "        service_level: float,\n",
    "            Target service level\n",
    "        max_occupancy: float,\n",
    "            The maximum fraction of time that a transaction can occupy a position\n",
    "        Returns\n",
    "        -------\n",
    "        raw_positions: int,\n",
    "            The required positions assuming shrinkage = 0\n",
    "        positions: int,\n",
    "            The number of positions needed to ensure the required service level\n",
    "        service_level: float,\n",
    "            The fraction of transactions that are expected to be assigned to a position,\n",
    "            before the asa time\n",
    "        occupancy: float,\n",
    "            The expected occupancy of positions\n",
    "        waiting_probability: float,\n",
    "            The probability of a transaction waiting in the queue\n",
    "        \"\"\"\n",
    "\n",
    "        if service_level < 0 or service_level > 1:\n",
    "            raise ValueError(\"service_level must be between 0 and 1\")\n",
    "\n",
    "        if max_occupancy < 0 or max_occupancy > 1:\n",
    "            raise ValueError(\"max_occupancy must be between 0 and 1\")\n",
    "\n",
    "        positions = round(self.intensity + 1)\n",
    "        achieved_service_level = self.service_level(positions, scale_positions=False)\n",
    "        while achieved_service_level < service_level:\n",
    "            positions += 1\n",
    "            achieved_service_level = self.service_level(positions, scale_positions=False)\n",
    "\n",
    "        achieved_occupancy = self.achieved_occupancy(positions, scale_positions=False)\n",
    "\n",
    "        raw_positions = ceil(positions)\n",
    "\n",
    "        if achieved_occupancy > max_occupancy:\n",
    "            raw_positions = ceil(self.intensity / max_occupancy)\n",
    "            achieved_occupancy = self.achieved_occupancy(raw_positions)\n",
    "            achieved_service_level = self.service_level(raw_positions)\n",
    "\n",
    "        waiting_probability = self.waiting_probability(positions=raw_positions)\n",
    "        positions = ceil(raw_positions / (1 - self.shrinkage))\n",
    "\n",
    "        return {\"raw_positions\": raw_positions,\n",
    "                \"positions\": positions,\n",
    "                \"service_level\": achieved_service_level,\n",
    "                \"occupancy\": achieved_occupancy,\n",
    "                \"waiting_probability\": waiting_probability}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d7a48e-3dbe-4837-81a4-ab1b8a7b4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tuple to pass service level goal, shrinkage, \n",
    "team_settings = {\n",
    "    'Commercial_Billing': (0.60, 0.05, 30, 30),\n",
    "    'Commercial_Sales': (0.60, 0.05, 30, 30),\n",
    "    'Cable_Sales': (0.65, 0.05, 30, 30),\n",
    "    'Cable_Retention': (0.65, 0.05, 30, 30),\n",
    "    'Cable_Seniors': (0.70, 0.05, 30, 30),\n",
    "    'Residential_FS': (0.65, 0.05, 30, 30),\n",
    "    'Commercial_FS': (0.65, 0.05, 30, 30),\n",
    "    'Wireline_Sales': (0.65, 0.10, 30, 30),\n",
    "    'Wireline_Retention': (0.65, 0.10, 30, 30),\n",
    "    'Wireline_Seniors': (0.70, 0.05, 30, 30),\n",
    "    'Continuum_Sales': (0.65, 0.05, 30, 30),\n",
    "    'Continuum_Retention': (0.65, 0.05, 30, 30),\n",
    "    'Continuum_Res_FS': (0.65, 0.05, 30, 30),\n",
    "    'Continuum_Bus_FS': (0.65, 0.05, 30, 30)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e6c6e12-90d4-4f6c-b59a-07b881f8f76d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(team_info, team, interval_df, data_type):\n",
    "    service_level_percent, shrinkage, reporting_period, service_level_time = team_info\n",
    "    results = []\n",
    "\n",
    "    for _, row in interval_df.iterrows():\n",
    "        transactions = row[f'{data_type}_CV']\n",
    "        aht = row[f'{data_type}_AHT']\n",
    "        interval = reporting_period\n",
    "        asa = service_level_time / 60\n",
    "\n",
    "        if transactions > 0 and aht > 0:\n",
    "            erlang = ErlangC(transactions=transactions, aht=aht, interval=interval, asa=asa, shrinkage=shrinkage)\n",
    "            positions_requirements = erlang.required_positions(service_level=service_level_percent)\n",
    "\n",
    "            result = {\n",
    "                'Team': team,\n",
    "                'Date': row['Date'],\n",
    "                'Time': row['Time'],\n",
    "                'Time_Interval': row['Time_Interval'],\n",
    "                f'{data_type}_CV': transactions,\n",
    "                f'{data_type}_AHT': aht,\n",
    "                f'{data_type}_Required_FTE': positions_requirements['positions'],\n",
    "                f'{data_type}_Raw_FTE': positions_requirements['raw_positions'],\n",
    "                f'Service_Level_{data_type}': positions_requirements['service_level'],\n",
    "                f'Occupancy_{data_type}': positions_requirements['occupancy'],\n",
    "                f'Waiting_Probablility_{data_type}': positions_requirements['waiting_probability'],\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "results = []\n",
    "for team, settings in team_settings.items():\n",
    "    team_df = call_data[call_data['Team'] == team]\n",
    "    actual_df = process_data(settings, team, team_df, 'Actual')\n",
    "    forecasted_df = process_data(settings, team, team_df, 'Forecasted')\n",
    "    result_df = actual_df.merge(forecasted_df, on=['Team', 'Date', 'Time', 'Time_Interval'], how='outer')\n",
    "    \n",
    "    if not result_df.empty:\n",
    "        results.append(result_df)\n",
    "\n",
    "final_results = pd.concat(results, ignore_index=True)\n",
    "final_results.fillna(0, inplace=True)\n",
    "final_results['Date'] = pd.to_datetime(final_results['Date'], format='%Y-%m-%d')\n",
    "final_results = final_results.sort_values(by=['Team', 'Date', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2ded1c9-7a55-41ed-8809-294127222312",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"I:\\\\GitHub\\\\forecasting\\\\accuracy\\\\accuracy_exports\\\\\"\n",
    "\n",
    "# Convert 'Date' column to datetime and create a new 'Month' column\n",
    "final_results['Date'] = pd.to_datetime(final_results['Date'])\n",
    "final_results['Month'] = final_results['Date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Export the data\n",
    "teams = final_results['Team'].unique()\n",
    "for team in teams:\n",
    "    team_result = final_results[final_results['Team'] == team]\n",
    "    for month in team_result['Month'].unique():\n",
    "        month_result = team_result[team_result['Month'] == month]\n",
    "        file_name = f\"{team}_{month}.txt\"\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        month_result.to_csv(file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d93d53e6-7615-4348-afed-85c997343793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usrocu\\AppData\\Local\\Temp\\ipykernel_4160\\4128373099.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pywfm['Date'] = pd.to_datetime(pywfm['Date'], format='%Y-%m-%d')\n",
      "C:\\Users\\usrocu\\AppData\\Local\\Temp\\ipykernel_4160\\4128373099.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  verint['Date'] = pd.to_datetime(verint['Date'], format='%Y-%m-%d')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Actual_CV_x</th>\n",
       "      <th>Forecasted_CV_x</th>\n",
       "      <th>Actual_AHT_x</th>\n",
       "      <th>Forecasted_AHT_x</th>\n",
       "      <th>Actual_CV_y</th>\n",
       "      <th>Forecasted_CV_y</th>\n",
       "      <th>Actual_AHT_y</th>\n",
       "      <th>Forecasted_AHT_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cable_Retention</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cable_Retention</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>08:30:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cable_Retention</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cable_Retention</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>09:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cable_Retention</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Team       Date      Time  Actual_CV_x  Forecasted_CV_x  \\\n",
       "0  Cable_Retention 2023-03-01  08:00:00         10.0              9.0   \n",
       "1  Cable_Retention 2023-03-01  08:30:00         12.0             11.0   \n",
       "2  Cable_Retention 2023-03-01  09:00:00         16.0             15.0   \n",
       "3  Cable_Retention 2023-03-01  09:30:00         20.0             19.0   \n",
       "4  Cable_Retention 2023-03-01  10:00:00         36.0             33.0   \n",
       "\n",
       "   Actual_AHT_x  Forecasted_AHT_x  Actual_CV_y  Forecasted_CV_y  Actual_AHT_y  \\\n",
       "0         445.0             454.0         10.0              9.0         445.0   \n",
       "1         514.0             464.0         12.0             11.0         514.0   \n",
       "2         433.0             467.0         16.0             15.0         433.0   \n",
       "3         441.0             471.0         20.0             19.0         441.0   \n",
       "4         508.0             512.0         36.0             33.0         508.0   \n",
       "\n",
       "   Forecasted_AHT_y  \n",
       "0             454.0  \n",
       "1             464.0  \n",
       "2             467.0  \n",
       "3             471.0  \n",
       "4             512.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pywfm = final_results[['Team', 'Date', 'Time', 'Actual_CV', 'Forecasted_CV', 'Actual_AHT', 'Forecasted_AHT']]\n",
    "verint = call_data[['Team', 'Date', 'Time', 'Actual_CV', 'Forecasted_CV', 'Actual_AHT', 'Forecasted_AHT']]\n",
    "pywfm['Date'] = pd.to_datetime(pywfm['Date'], format='%Y-%m-%d')\n",
    "verint['Date'] = pd.to_datetime(verint['Date'], format='%Y-%m-%d')\n",
    "table = pywfm.merge(verint, on=['Team', 'Date', 'Time'], how='outer')\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3712ba6c-04c6-4451-aa9a-ff884b313ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(f'{directory}_test.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f982a4-8063-4fd5-ba99-4085a93691e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
